app: vjepa
data:
  batch_size: 28
  clip_duration: null
  crop_size: 224
  dataset_type: VideoDataset
  datasets:
  - /media/backup_16TB/sean/VJEPA/jepa/configs/pretrain_a6000/vit_tiny/full_list.csv
  decode_one_clip: true
  filter_short_videos: false
  num_clips: 1
  num_frames: 16
  num_workers: 6
  patch_size: 16
  pin_mem: true
  sampling_rate: 4
  tubelet_size: 2
data_aug:
  auto_augment: false
  motion_shift: false
  random_resize_aspect_ratio:
  - 1
  - 1
  random_resize_scale:
  - 0.7
  - 1.0
  reprob: 0.0
  normalize:
  - - 0.347
    - 0.347
    - 0.347
  - - 0.346
    - 0.346
    - 0.346
logging:
  folder: /media/backup_16TB/sean/VJEPA/a6000_output/vit_base
  write_tag: vitbase_fix18_ctn_100epoch
  project: voxel-jepa-vit-base-pretraining # Don't change this
  run_name: vitbase_fix18_ctn_100epoch # Please change every time before running, this is the name for wandb run file

loss:
  loss_exp: 1.0
  reg_coeff: 0.0
mask:
- aspect_ratio:
  - 1
  - 1
  max_keep: null
  max_temporal_keep: 1.0
  num_blocks: 4
  spatial_scale:
  - 0.20
  - 0.20
  temporal_scale:
  - 1.0
  - 1.0
- aspect_ratio:
  - 1
  - 1
  max_keep: null
  max_temporal_keep: 1.0
  num_blocks: 4
  spatial_scale:
  - 0.20
  - 0.20
  temporal_scale:
  - 1.0
  - 1.0



meta:
  dtype: bfloat16
  eval_freq: 5
  load_checkpoint: true
  read_checkpoint: /media/backup_16TB/sean/VJEPA/a6000_output/vit_base/vitbase_fix18-latest.pth.tar
  seed: 234
  use_sdpa: true
model:
  model_name: vit_base
  pred_depth: 12
  pred_embed_dim: 384
  uniform_power: true
  use_mask_tokens: true
  zero_init_mask_tokens: true
nodes: 1
optimization:
  clip_grad: 10.0
  ema:
  - 0.998
  - 1.0
  epochs: 200 #300
  final_lr: 1.0e-06
  final_weight_decay: 0.4
  # ipe: 1266 #1082
  ipe_scale: 1.25
  lr: 0.000625
  start_lr: 0.000625
  warmup: 0
  weight_decay: 0.04
tasks_per_node: 1
port: 42001
