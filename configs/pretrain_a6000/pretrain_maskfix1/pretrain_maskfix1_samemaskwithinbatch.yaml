app: vjepa
data:
  batch_size: 12
  clip_duration: null
  crop_size: 224
  dataset_type: VideoDataset
  datasets:
  - /media/backup_16TB/sean/VJEPA/jepa/configs/pretrain_a6000/pretrain_maskfix1/pretrain_maskfix1.csv
  decode_one_clip: true
  filter_short_videos: false
  num_clips: 1
  num_frames: 16
  num_workers: 6
  patch_size: 16
  pin_mem: true
  sampling_rate: 4
  tubelet_size: 2
data_aug:
  auto_augment: false
  motion_shift: false
  random_resize_aspect_ratio:
  - 0.75
  - 1.35
  random_resize_scale:
  - 0.3
  - 1.0
  reprob: 0.0
logging:
  folder: /media/backup_16TB/sean/VJEPA/a6000_output/pretrain_maskfix1_tiny
  write_tag: vittiny_maskfix1_samemaskwithinbatch
  project: voxel-jepa-pretraining # Don't change this
  run_name: a6000 vittiny_maskfix1_samemaskwithinbatch # Please change every time before running, this is the name for wandb run file

loss:
  loss_exp: 1.0
  reg_coeff: 0.0
mask:
- aspect_ratio:
  - 1
  - 1
  max_keep: null
  max_temporal_keep: 1.0
  num_blocks: 8
  spatial_scale:
  - 0.15
  - 0.15
  temporal_scale:
  - 1.0
  - 1.0


meta:
  dtype: bfloat16
  eval_freq: 5
  load_checkpoint: false
  read_checkpoint: /local_data/sean_hasitha/sean/VJEPA/jepa/vitl16.pth.tar
  seed: 234
  use_sdpa: true
model:
  model_name: vit_tiny
  pred_depth: 12
  pred_embed_dim: 384
  uniform_power: true
  use_mask_tokens: true
  zero_init_mask_tokens: true
nodes: 1
optimization:
  clip_grad: 10.0
  ema:
  - 0.998
  - 1.0
  epochs: 300 #300
  final_lr: 1.0e-06
  final_weight_decay: 0.4
  ipe: 1266 #1082
  ipe_scale: 1.25
  lr: 0.000625
  start_lr: 0.001
  warmup: 40
  weight_decay: 0.04
tasks_per_node: 1
