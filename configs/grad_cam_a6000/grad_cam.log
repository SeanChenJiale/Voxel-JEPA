INFO:root:called-params /media/backup_16TB/sean/VJEPA/jepa/configs/grad_cam_a6000/grad_cam.yaml
INFO:root:loaded params...
{   'data': {   'dataset_val': '/media/backup_16TB/sean/VJEPA/jepa/configs/grad_cam_a6000/Brainslice_48_ADclassification_val_final_filtered.csv',
                'frame_step': 4,
                'frames_per_clip': 16,
                'num_classes': 2,
                'num_segments': 1,
                'num_views_per_segment': 1,
                'num_workers': 6},
    'data_aug': {   'auto_augment': False,
                    'motion_shift': False,
                    'normalize': [[0.347, 0.347, 0.347], [0.346, 0.346, 0.346]],
                    'random_resize_aspect_ratio': [0.75, 1.35],
                    'random_resize_scale': [0.3, 1.0],
                    'reprob': 0.0},
    'eval_name': 'video_grad_cam',
    'logging': {'project': 'gradcam', 'run_name': 'gradcam'},
    'nodes': 1,
    'optimization': {   'attend_across_segments': False,
                        'batch_size': 1,
                        'final_lr': 0.0,
                        'lr': 0.0005,
                        'num_epochs': 1,
                        'resolution': 224,
                        'start_lr': 0.0005,
                        'use_bfloat16': True,
                        'warmup': 0.0,
                        'weight_decay': 0.005},
    'port': 42005,
    'pretrain': {   'checkpoint': 'vitbase_fix18_ctn_100epoch_from_k400-latest.pth.tar',
                    'checkpoint_key': 'target_encoder',
                    'clip_duration': None,
                    'folder': '/media/backup_16TB/sean/VJEPA/a6000_output/vit_base/K400/',
                    'frames_per_clip': 16,
                    'model_name': 'vit_base',
                    'patch_size': 16,
                    'tight_silu': False,
                    'tubelet_size': 2,
                    'uniform_power': True,
                    'use_sdpa': True,
                    'use_silu': False,
                    'write_tag': 'vit_base_k400andMRI'},
    'resume_checkpoint': False,
    'tag': 'vit_base_k400andMRI',
    'tasks_per_node': 1}
INFO:root:Running... (rank: 0/1)
INFO:root:Running evaluation: video_grad_cam
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:Loading pretrained model from /media/backup_16TB/sean/VJEPA/a6000_output/vit_base/K400/vitbase_fix18_ctn_100epoch_from_k400-latest.pth.tar
VisionTransformer(
  (patch_embed): PatchEmbed3D(
    (proj): Conv3d(3, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
INFO:root:loaded pretrained model with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch: 200
 path: /media/backup_16TB/sean/VJEPA/a6000_output/vit_base/K400/vitbase_fix18_ctn_100epoch_from_k400-latest.pth.tar
INFO:root:Loading checkpoint from: /media/backup_16TB/sean/VJEPA/a6000_output/vit_base/K400/video_classification_frozen/vit_base_k400andMRI/vit_base_k400andMRI-latest.pth.tar
INFO:root:Successfully loaded weights from checkpoint: /media/backup_16TB/sean/VJEPA/a6000_output/vit_base/K400/video_classification_frozen/vit_base_k400andMRI/vit_base_k400andMRI-latest.pth.tar
INFO:root:VideoDataset dataset created
INFO:root:VideoDataset unsupervised data loader created
INFO:root:Dataloader created... iterations per epoch: 1
AttentiveClassifier(
  (pooler): AttentivePooler(
    (cross_attention_block): CrossAttentionBlock(
      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (xattn): CrossAttention(
        (q): Linear(in_features=768, out_features=768, bias=True)
        (kv): Linear(in_features=768, out_features=1536, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
      )
      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (linear): Linear(in_features=768, out_features=2, bias=True)
)
5
[[tensor([[[[[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]],

          [[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]],

          [[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]],

          ...,

          [[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]],

          [[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]],

          [[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]]],


         [[[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]],

          [[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]],

          [[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]],

          ...,

          [[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]],

          [[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]],

          [[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]]],


         [[[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -0.9916, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]],

          [[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -0.9916, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]],

          [[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]],

          ...,

          [[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]],

          [[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]],

          [[-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           ...,
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029],
           [-1.0029, -1.0029, -1.0029,  ..., -1.0029, -1.0029, -1.0029]]]]])]]Process Process-1:
Traceback (most recent call last):
  File "/home/sean/anaconda3/envs/jepa/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/sean/anaconda3/envs/jepa/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/media/backup_16TB/sean/VJEPA/jepa/evals/main.py", line 89, in process_main
    eval_main(params['eval_name'], args_eval=params,plotter=plotter, validation=validation, debug=debug, grad_cam=grad_cam)
  File "/media/backup_16TB/sean/VJEPA/jepa/evals/scaffold.py", line 36, in main
    return importlib.import_module(f'evals.{eval_name}.eval').main(
  File "/media/backup_16TB/sean/VJEPA/jepa/evals/video_grad_cam/eval.py", line 400, in main
    scaler=scaler,
NameError: name 'scaler' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/sean/anaconda3/envs/jepa/lib/python3.9/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/home/sean/anaconda3/envs/jepa/lib/python3.9/multiprocessing/util.py", line 357, in _exit_function
    p.join()
  File "/home/sean/anaconda3/envs/jepa/lib/python3.9/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/home/sean/anaconda3/envs/jepa/lib/python3.9/multiprocessing/popen_fork.py", line 43, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/home/sean/anaconda3/envs/jepa/lib/python3.9/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/sean/anaconda3/envs/jepa/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 4113996) is killed by signal: Terminated. 

tensor([0])
[tensor([[ 0,  4,  8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60]])]
['/media/backup_16TB/sean/Monai/BrainSlice48_zoom/ADNI_MPRAGE/2013-04-22_12_22_25.0_MPRAGE_SENSE_20130422122225_301/Axial.mp4']
tensor([0])
