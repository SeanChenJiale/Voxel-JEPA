{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file = \"/home/tianze/DATA_2T/MRI/csv_for_finetuning/ad_cn/OASIS3_final.csv\"\n",
    "df = pd.read_csv(\n",
    "    csv_file,\n",
    "    sep=\" \",\n",
    "    header=None\n",
    ")\n",
    "\n",
    "# df.columns = [\"filename\", \"label\"]\n",
    "df.columns = [\"filename\", \"axis\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>axis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30001_s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30059_s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30131_s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30141_s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30105_s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>/home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30089_s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>/home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30098_s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>/home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30043_s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>/home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30154_s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>/home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30122_s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filename  axis  label\n",
       "0    /home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30001_s...     0      0\n",
       "1    /home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30059_s...     0      0\n",
       "2    /home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30131_s...     0      0\n",
       "3    /home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30141_s...     0      0\n",
       "4    /home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30105_s...     0      0\n",
       "..                                                 ...   ...    ...\n",
       "104  /home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30089_s...     0      0\n",
       "105  /home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30098_s...     0      1\n",
       "106  /home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30043_s...     0      1\n",
       "107  /home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30154_s...     0      0\n",
       "108  /home/tianze/DATA_2T/MRI/OASIS3/sub-OAS30122_s...     0      0\n",
       "\n",
       "[109 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution:\n",
      "label\n",
      "0    78\n",
      "1    31\n",
      "Name: count, dtype: int64\n",
      "Sum: 109\n",
      "Ratio: 0.7156\n"
     ]
    }
   ],
   "source": [
    "print(\"Label distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "count_0 = (df['label'] == 0).sum()\n",
    "count_1 = (df['label'] == 1).sum()\n",
    "ratio = count_0 / (count_0 + count_1)\n",
    "print(f\"Sum: {count_0+count_1}\")\n",
    "print(f\"Ratio: {ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/backup_16TB/K400/videos_val/klx5NcYwFzI.mp4'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_root = \"/media/backup_16TB/\"\n",
    "new_root = \"/home/tianze/DATA_2T/\"\n",
    "\n",
    "df[\"filename\"] = df[\"filename\"].str.replace(old_root, new_root, regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/tianze/DATA_2T/K400/videos_val/klx5NcYwF...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/tianze/DATA_2T/K400/videos_val/x3DmBCS9m...</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/tianze/DATA_2T/K400/videos_val/y6P2ZtZF9...</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/tianze/DATA_2T/K400/videos_val/6P2eVJ-Qp...</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/tianze/DATA_2T/K400/videos_val/KXYTyVaZV...</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15787</th>\n",
       "      <td>/home/tianze/DATA_2T/K400/videos_val/G0XJmZVO8...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15788</th>\n",
       "      <td>/home/tianze/DATA_2T/K400/videos_val/u-2dUczeb...</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15789</th>\n",
       "      <td>/home/tianze/DATA_2T/K400/videos_val/iO8RYYQzN...</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15790</th>\n",
       "      <td>/home/tianze/DATA_2T/K400/videos_val/-lKtqHLTM...</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15791</th>\n",
       "      <td>/home/tianze/DATA_2T/K400/videos_val/KZrUX5r1P...</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                filename  label\n",
       "0      /home/tianze/DATA_2T/K400/videos_val/klx5NcYwF...     72\n",
       "1      /home/tianze/DATA_2T/K400/videos_val/x3DmBCS9m...    121\n",
       "2      /home/tianze/DATA_2T/K400/videos_val/y6P2ZtZF9...     69\n",
       "3      /home/tianze/DATA_2T/K400/videos_val/6P2eVJ-Qp...    131\n",
       "4      /home/tianze/DATA_2T/K400/videos_val/KXYTyVaZV...    219\n",
       "...                                                  ...    ...\n",
       "15787  /home/tianze/DATA_2T/K400/videos_val/G0XJmZVO8...    101\n",
       "15788  /home/tianze/DATA_2T/K400/videos_val/u-2dUczeb...    212\n",
       "15789  /home/tianze/DATA_2T/K400/videos_val/iO8RYYQzN...    191\n",
       "15790  /home/tianze/DATA_2T/K400/videos_val/-lKtqHLTM...    195\n",
       "15791  /home/tianze/DATA_2T/K400/videos_val/KZrUX5r1P...    346\n",
       "\n",
       "[15792 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "    csv_file,\n",
    "    sep=\" \",\n",
    "    header=False,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianze/anaconda3/envs/videomae/lib/python3.10/site-packages/torch/cuda/__init__.py:51: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"./checkpoints/vit_base_K400_pretrain_800epochs/checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_token: torch.Size([1, 1, 384])\n",
      "encoder.patch_embed.proj.weight: torch.Size([768, 3, 2, 16, 16])\n",
      "encoder.patch_embed.proj.bias: torch.Size([768])\n",
      "encoder.blocks.0.norm1.weight: torch.Size([768])\n",
      "encoder.blocks.0.norm1.bias: torch.Size([768])\n",
      "encoder.blocks.0.attn.q_bias: torch.Size([768])\n",
      "encoder.blocks.0.attn.v_bias: torch.Size([768])\n",
      "encoder.blocks.0.attn.qkv.weight: torch.Size([2304, 768])\n",
      "encoder.blocks.0.attn.proj.weight: torch.Size([768, 768])\n",
      "encoder.blocks.0.attn.proj.bias: torch.Size([768])\n",
      "encoder.blocks.0.norm2.weight: torch.Size([768])\n",
      "encoder.blocks.0.norm2.bias: torch.Size([768])\n",
      "encoder.blocks.0.mlp.fc1.weight: torch.Size([3072, 768])\n",
      "encoder.blocks.0.mlp.fc1.bias: torch.Size([3072])\n",
      "encoder.blocks.0.mlp.fc2.weight: torch.Size([768, 3072])\n",
      "encoder.blocks.0.mlp.fc2.bias: torch.Size([768])\n",
      "encoder.blocks.1.norm1.weight: torch.Size([768])\n",
      "encoder.blocks.1.norm1.bias: torch.Size([768])\n",
      "encoder.blocks.1.attn.q_bias: torch.Size([768])\n",
      "encoder.blocks.1.attn.v_bias: torch.Size([768])\n",
      "encoder.blocks.1.attn.qkv.weight: torch.Size([2304, 768])\n",
      "encoder.blocks.1.attn.proj.weight: torch.Size([768, 768])\n",
      "encoder.blocks.1.attn.proj.bias: torch.Size([768])\n",
      "encoder.blocks.1.norm2.weight: torch.Size([768])\n",
      "encoder.blocks.1.norm2.bias: torch.Size([768])\n",
      "encoder.blocks.1.mlp.fc1.weight: torch.Size([3072, 768])\n",
      "encoder.blocks.1.mlp.fc1.bias: torch.Size([3072])\n",
      "encoder.blocks.1.mlp.fc2.weight: torch.Size([768, 3072])\n",
      "encoder.blocks.1.mlp.fc2.bias: torch.Size([768])\n",
      "encoder.blocks.2.norm1.weight: torch.Size([768])\n",
      "encoder.blocks.2.norm1.bias: torch.Size([768])\n",
      "encoder.blocks.2.attn.q_bias: torch.Size([768])\n",
      "encoder.blocks.2.attn.v_bias: torch.Size([768])\n",
      "encoder.blocks.2.attn.qkv.weight: torch.Size([2304, 768])\n",
      "encoder.blocks.2.attn.proj.weight: torch.Size([768, 768])\n",
      "encoder.blocks.2.attn.proj.bias: torch.Size([768])\n",
      "encoder.blocks.2.norm2.weight: torch.Size([768])\n",
      "encoder.blocks.2.norm2.bias: torch.Size([768])\n",
      "encoder.blocks.2.mlp.fc1.weight: torch.Size([3072, 768])\n",
      "encoder.blocks.2.mlp.fc1.bias: torch.Size([3072])\n",
      "encoder.blocks.2.mlp.fc2.weight: torch.Size([768, 3072])\n",
      "encoder.blocks.2.mlp.fc2.bias: torch.Size([768])\n",
      "encoder.blocks.3.norm1.weight: torch.Size([768])\n",
      "encoder.blocks.3.norm1.bias: torch.Size([768])\n",
      "encoder.blocks.3.attn.q_bias: torch.Size([768])\n",
      "encoder.blocks.3.attn.v_bias: torch.Size([768])\n",
      "encoder.blocks.3.attn.qkv.weight: torch.Size([2304, 768])\n",
      "encoder.blocks.3.attn.proj.weight: torch.Size([768, 768])\n",
      "encoder.blocks.3.attn.proj.bias: torch.Size([768])\n",
      "encoder.blocks.3.norm2.weight: torch.Size([768])\n",
      "encoder.blocks.3.norm2.bias: torch.Size([768])\n",
      "encoder.blocks.3.mlp.fc1.weight: torch.Size([3072, 768])\n",
      "encoder.blocks.3.mlp.fc1.bias: torch.Size([3072])\n",
      "encoder.blocks.3.mlp.fc2.weight: torch.Size([768, 3072])\n",
      "encoder.blocks.3.mlp.fc2.bias: torch.Size([768])\n",
      "encoder.blocks.4.norm1.weight: torch.Size([768])\n",
      "encoder.blocks.4.norm1.bias: torch.Size([768])\n",
      "encoder.blocks.4.attn.q_bias: torch.Size([768])\n",
      "encoder.blocks.4.attn.v_bias: torch.Size([768])\n",
      "encoder.blocks.4.attn.qkv.weight: torch.Size([2304, 768])\n",
      "encoder.blocks.4.attn.proj.weight: torch.Size([768, 768])\n",
      "encoder.blocks.4.attn.proj.bias: torch.Size([768])\n",
      "encoder.blocks.4.norm2.weight: torch.Size([768])\n",
      "encoder.blocks.4.norm2.bias: torch.Size([768])\n",
      "encoder.blocks.4.mlp.fc1.weight: torch.Size([3072, 768])\n",
      "encoder.blocks.4.mlp.fc1.bias: torch.Size([3072])\n",
      "encoder.blocks.4.mlp.fc2.weight: torch.Size([768, 3072])\n",
      "encoder.blocks.4.mlp.fc2.bias: torch.Size([768])\n",
      "encoder.blocks.5.norm1.weight: torch.Size([768])\n",
      "encoder.blocks.5.norm1.bias: torch.Size([768])\n",
      "encoder.blocks.5.attn.q_bias: torch.Size([768])\n",
      "encoder.blocks.5.attn.v_bias: torch.Size([768])\n",
      "encoder.blocks.5.attn.qkv.weight: torch.Size([2304, 768])\n",
      "encoder.blocks.5.attn.proj.weight: torch.Size([768, 768])\n",
      "encoder.blocks.5.attn.proj.bias: torch.Size([768])\n",
      "encoder.blocks.5.norm2.weight: torch.Size([768])\n",
      "encoder.blocks.5.norm2.bias: torch.Size([768])\n",
      "encoder.blocks.5.mlp.fc1.weight: torch.Size([3072, 768])\n",
      "encoder.blocks.5.mlp.fc1.bias: torch.Size([3072])\n",
      "encoder.blocks.5.mlp.fc2.weight: torch.Size([768, 3072])\n",
      "encoder.blocks.5.mlp.fc2.bias: torch.Size([768])\n",
      "encoder.blocks.6.norm1.weight: torch.Size([768])\n",
      "encoder.blocks.6.norm1.bias: torch.Size([768])\n",
      "encoder.blocks.6.attn.q_bias: torch.Size([768])\n",
      "encoder.blocks.6.attn.v_bias: torch.Size([768])\n",
      "encoder.blocks.6.attn.qkv.weight: torch.Size([2304, 768])\n",
      "encoder.blocks.6.attn.proj.weight: torch.Size([768, 768])\n",
      "encoder.blocks.6.attn.proj.bias: torch.Size([768])\n",
      "encoder.blocks.6.norm2.weight: torch.Size([768])\n",
      "encoder.blocks.6.norm2.bias: torch.Size([768])\n",
      "encoder.blocks.6.mlp.fc1.weight: torch.Size([3072, 768])\n",
      "encoder.blocks.6.mlp.fc1.bias: torch.Size([3072])\n",
      "encoder.blocks.6.mlp.fc2.weight: torch.Size([768, 3072])\n",
      "encoder.blocks.6.mlp.fc2.bias: torch.Size([768])\n",
      "encoder.blocks.7.norm1.weight: torch.Size([768])\n",
      "encoder.blocks.7.norm1.bias: torch.Size([768])\n",
      "encoder.blocks.7.attn.q_bias: torch.Size([768])\n",
      "encoder.blocks.7.attn.v_bias: torch.Size([768])\n",
      "encoder.blocks.7.attn.qkv.weight: torch.Size([2304, 768])\n",
      "encoder.blocks.7.attn.proj.weight: torch.Size([768, 768])\n",
      "encoder.blocks.7.attn.proj.bias: torch.Size([768])\n",
      "encoder.blocks.7.norm2.weight: torch.Size([768])\n",
      "encoder.blocks.7.norm2.bias: torch.Size([768])\n",
      "encoder.blocks.7.mlp.fc1.weight: torch.Size([3072, 768])\n",
      "encoder.blocks.7.mlp.fc1.bias: torch.Size([3072])\n",
      "encoder.blocks.7.mlp.fc2.weight: torch.Size([768, 3072])\n",
      "encoder.blocks.7.mlp.fc2.bias: torch.Size([768])\n",
      "encoder.blocks.8.norm1.weight: torch.Size([768])\n",
      "encoder.blocks.8.norm1.bias: torch.Size([768])\n",
      "encoder.blocks.8.attn.q_bias: torch.Size([768])\n",
      "encoder.blocks.8.attn.v_bias: torch.Size([768])\n",
      "encoder.blocks.8.attn.qkv.weight: torch.Size([2304, 768])\n",
      "encoder.blocks.8.attn.proj.weight: torch.Size([768, 768])\n",
      "encoder.blocks.8.attn.proj.bias: torch.Size([768])\n",
      "encoder.blocks.8.norm2.weight: torch.Size([768])\n",
      "encoder.blocks.8.norm2.bias: torch.Size([768])\n",
      "encoder.blocks.8.mlp.fc1.weight: torch.Size([3072, 768])\n",
      "encoder.blocks.8.mlp.fc1.bias: torch.Size([3072])\n",
      "encoder.blocks.8.mlp.fc2.weight: torch.Size([768, 3072])\n",
      "encoder.blocks.8.mlp.fc2.bias: torch.Size([768])\n",
      "encoder.blocks.9.norm1.weight: torch.Size([768])\n",
      "encoder.blocks.9.norm1.bias: torch.Size([768])\n",
      "encoder.blocks.9.attn.q_bias: torch.Size([768])\n",
      "encoder.blocks.9.attn.v_bias: torch.Size([768])\n",
      "encoder.blocks.9.attn.qkv.weight: torch.Size([2304, 768])\n",
      "encoder.blocks.9.attn.proj.weight: torch.Size([768, 768])\n",
      "encoder.blocks.9.attn.proj.bias: torch.Size([768])\n",
      "encoder.blocks.9.norm2.weight: torch.Size([768])\n",
      "encoder.blocks.9.norm2.bias: torch.Size([768])\n",
      "encoder.blocks.9.mlp.fc1.weight: torch.Size([3072, 768])\n",
      "encoder.blocks.9.mlp.fc1.bias: torch.Size([3072])\n",
      "encoder.blocks.9.mlp.fc2.weight: torch.Size([768, 3072])\n",
      "encoder.blocks.9.mlp.fc2.bias: torch.Size([768])\n",
      "encoder.blocks.10.norm1.weight: torch.Size([768])\n",
      "encoder.blocks.10.norm1.bias: torch.Size([768])\n",
      "encoder.blocks.10.attn.q_bias: torch.Size([768])\n",
      "encoder.blocks.10.attn.v_bias: torch.Size([768])\n",
      "encoder.blocks.10.attn.qkv.weight: torch.Size([2304, 768])\n",
      "encoder.blocks.10.attn.proj.weight: torch.Size([768, 768])\n",
      "encoder.blocks.10.attn.proj.bias: torch.Size([768])\n",
      "encoder.blocks.10.norm2.weight: torch.Size([768])\n",
      "encoder.blocks.10.norm2.bias: torch.Size([768])\n",
      "encoder.blocks.10.mlp.fc1.weight: torch.Size([3072, 768])\n",
      "encoder.blocks.10.mlp.fc1.bias: torch.Size([3072])\n",
      "encoder.blocks.10.mlp.fc2.weight: torch.Size([768, 3072])\n",
      "encoder.blocks.10.mlp.fc2.bias: torch.Size([768])\n",
      "encoder.blocks.11.norm1.weight: torch.Size([768])\n",
      "encoder.blocks.11.norm1.bias: torch.Size([768])\n",
      "encoder.blocks.11.attn.q_bias: torch.Size([768])\n",
      "encoder.blocks.11.attn.v_bias: torch.Size([768])\n",
      "encoder.blocks.11.attn.qkv.weight: torch.Size([2304, 768])\n",
      "encoder.blocks.11.attn.proj.weight: torch.Size([768, 768])\n",
      "encoder.blocks.11.attn.proj.bias: torch.Size([768])\n",
      "encoder.blocks.11.norm2.weight: torch.Size([768])\n",
      "encoder.blocks.11.norm2.bias: torch.Size([768])\n",
      "encoder.blocks.11.mlp.fc1.weight: torch.Size([3072, 768])\n",
      "encoder.blocks.11.mlp.fc1.bias: torch.Size([3072])\n",
      "encoder.blocks.11.mlp.fc2.weight: torch.Size([768, 3072])\n",
      "encoder.blocks.11.mlp.fc2.bias: torch.Size([768])\n",
      "encoder.norm.weight: torch.Size([768])\n",
      "encoder.norm.bias: torch.Size([768])\n",
      "decoder.blocks.0.norm1.weight: torch.Size([384])\n",
      "decoder.blocks.0.norm1.bias: torch.Size([384])\n",
      "decoder.blocks.0.attn.q_bias: torch.Size([384])\n",
      "decoder.blocks.0.attn.v_bias: torch.Size([384])\n",
      "decoder.blocks.0.attn.qkv.weight: torch.Size([1152, 384])\n",
      "decoder.blocks.0.attn.proj.weight: torch.Size([384, 384])\n",
      "decoder.blocks.0.attn.proj.bias: torch.Size([384])\n",
      "decoder.blocks.0.norm2.weight: torch.Size([384])\n",
      "decoder.blocks.0.norm2.bias: torch.Size([384])\n",
      "decoder.blocks.0.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "decoder.blocks.0.mlp.fc1.bias: torch.Size([1536])\n",
      "decoder.blocks.0.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "decoder.blocks.0.mlp.fc2.bias: torch.Size([384])\n",
      "decoder.blocks.1.norm1.weight: torch.Size([384])\n",
      "decoder.blocks.1.norm1.bias: torch.Size([384])\n",
      "decoder.blocks.1.attn.q_bias: torch.Size([384])\n",
      "decoder.blocks.1.attn.v_bias: torch.Size([384])\n",
      "decoder.blocks.1.attn.qkv.weight: torch.Size([1152, 384])\n",
      "decoder.blocks.1.attn.proj.weight: torch.Size([384, 384])\n",
      "decoder.blocks.1.attn.proj.bias: torch.Size([384])\n",
      "decoder.blocks.1.norm2.weight: torch.Size([384])\n",
      "decoder.blocks.1.norm2.bias: torch.Size([384])\n",
      "decoder.blocks.1.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "decoder.blocks.1.mlp.fc1.bias: torch.Size([1536])\n",
      "decoder.blocks.1.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "decoder.blocks.1.mlp.fc2.bias: torch.Size([384])\n",
      "decoder.blocks.2.norm1.weight: torch.Size([384])\n",
      "decoder.blocks.2.norm1.bias: torch.Size([384])\n",
      "decoder.blocks.2.attn.q_bias: torch.Size([384])\n",
      "decoder.blocks.2.attn.v_bias: torch.Size([384])\n",
      "decoder.blocks.2.attn.qkv.weight: torch.Size([1152, 384])\n",
      "decoder.blocks.2.attn.proj.weight: torch.Size([384, 384])\n",
      "decoder.blocks.2.attn.proj.bias: torch.Size([384])\n",
      "decoder.blocks.2.norm2.weight: torch.Size([384])\n",
      "decoder.blocks.2.norm2.bias: torch.Size([384])\n",
      "decoder.blocks.2.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "decoder.blocks.2.mlp.fc1.bias: torch.Size([1536])\n",
      "decoder.blocks.2.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "decoder.blocks.2.mlp.fc2.bias: torch.Size([384])\n",
      "decoder.blocks.3.norm1.weight: torch.Size([384])\n",
      "decoder.blocks.3.norm1.bias: torch.Size([384])\n",
      "decoder.blocks.3.attn.q_bias: torch.Size([384])\n",
      "decoder.blocks.3.attn.v_bias: torch.Size([384])\n",
      "decoder.blocks.3.attn.qkv.weight: torch.Size([1152, 384])\n",
      "decoder.blocks.3.attn.proj.weight: torch.Size([384, 384])\n",
      "decoder.blocks.3.attn.proj.bias: torch.Size([384])\n",
      "decoder.blocks.3.norm2.weight: torch.Size([384])\n",
      "decoder.blocks.3.norm2.bias: torch.Size([384])\n",
      "decoder.blocks.3.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "decoder.blocks.3.mlp.fc1.bias: torch.Size([1536])\n",
      "decoder.blocks.3.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "decoder.blocks.3.mlp.fc2.bias: torch.Size([384])\n",
      "decoder.norm.weight: torch.Size([384])\n",
      "decoder.norm.bias: torch.Size([384])\n",
      "decoder.head.weight: torch.Size([1536, 384])\n",
      "decoder.head.bias: torch.Size([1536])\n",
      "encoder_to_decoder.weight: torch.Size([384, 768])\n"
     ]
    }
   ],
   "source": [
    "for key, value in ckpt['model'].items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"{key}: {value.shape}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videomae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
